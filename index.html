<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <title>Witprocam by seanogden</title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1>Witprocam</h1>
          <h2></h2>
        </header>

        <section id="downloads" class="clearfix">
          <a href="https://github.com/seanogden/witprocam/zipball/master" id="download-zip" class="button"><span>Download .zip</span></a>
          <a href="https://github.com/seanogden/witprocam/tarball/master" id="download-tar-gz" class="button"><span>Download .tar.gz</span></a>
          <a href="https://github.com/seanogden/witprocam" id="view-on-github" class="button"><span>View on GitHub</span></a>
        </section>

        <hr>

        <section id="main_content">
          <h3>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h3>

<p>Imagine you’re a criminal and you’ve just abducted a wealthy individual, but now you need to make a video to express your demands for ransom.  Obviously you’d like to conceal your identity in said video but you’re a busy kidnapper and you don’t have time for video production and the post processing involved.  This is where our anonymizer comes in.  Using the technology we’ve developed, you can record a video that automatically blurs your face and disguises your voice as you record.  No post processing necessary.</p>

<p>In seriousness, our project idea was born from a problem familiar to all graduate students:  maximizing free food consumption.  The department regularly leaves leftover seminar food in the PhD kitchen, but the students prefer not to constantly check the kitchen for free food.  A mailing list called CS Vultures was created to alert all of the hungry graduate students to availability of free food.  However, not everyone participated in the mailing list, so a more automated solution was desired.  The idea of placing a live streaming camera in the kitchen was proposed, but it was quickly shot down by the administration due to university policy issues and privacy concerns.</p>

<p>Our project solves the problem of privacy concern with live-streaming by automatically detecting the faces on the screen and blurring them out in real time.  The automated nature and speed are what set our approach apart from the standard workflow of post-processing videos to blur out contents.</p>

<p>If you're using the GitHub for Mac, simply sync your repository and you'll see the new branch.</p>

<h3>
<a id="high-level-design" class="anchor" href="#high-level-design" aria-hidden="true"><span class="octicon octicon-link"></span></a>High level design</h3>

<p>We've crafted some handsome templates for you to use. Go ahead and continue to layouts to browse through them. You can easily go back to edit your page before publishing. After publishing your page, you can revisit the page generator and switch to another theme. Your Page content will be preserved if it remained markdown format.</p>

<h3>
<a id="hardware-design" class="anchor" href="#hardware-design" aria-hidden="true"><span class="octicon octicon-link"></span></a>Hardware design</h3>

<p>The entire project is implemented entirely in hardware, there is no CPU and no software.  The trickiest part of this project was the audio, mostly because of the need to figure out the Altera FFT module, and debugging the timing of the pipeline as well as fixed point overflow issues.</p>

<p>The video is shown in the RTL diagram below.
<img src="images/Pixelator.svg" alt=""></p>

<p>The audio pipeline is depicted in the RTL diagram below.
<img src="images/Phase-Vocoder.svg" alt=""></p>

<h3>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h3>

<p>The video processing is fast enough so that no artifacts are visible on the screen.  The skin detection updating is also fast enough that we are not able to move our faces fast enough to escape the blur effect.  Once the skin detection threshold is properly tuned for the lighting conditions, it is very accurate.</p>

<p>The audio processing is pipelined so that we can run both the inverse FFT for one stage and the FFT for the next stage simultaenously.  The FFT and inverse FFT modules are each implemented as four parallel quad-output FFTs.  The FFT runs in approximately 500 cycles at 50MHZ, and our audio sample rate is 48KHZ.  Ultimately, the ability to do so much of the computation in parallel on the FPGA makes it possible to run the entire audio pipeline in one audio sample period.</p>

<h3>
<a id="conclusions" class="anchor" href="#conclusions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusions</h3>

<p>The video pixelator design works very well, and exceeded our expectations.  Once tuned properly for lighting conditions, the blur effect is surprisingly accurate and robust.</p>

<p>While it is fast enough, our audio processing pipeline didn’t quite live up to our expectations based on our matlab model of the phase vocoder.  We were able to get a Donald Duck-like effect for the voice, but there are some noticeable artifacts in the output.  Our plan is to make the phase vocoder adjustable so that we can raise or lower the pitch of the input voice and fix the artifacts.</p>

<h3>
<a id="intellectual-property" class="anchor" href="#intellectual-property" aria-hidden="true"><span class="octicon octicon-link"></span></a>Intellectual Property</h3>

<p>We based our initial design on a previous year project [PROJECT LINK], which was in turn based on the Altera TV example and Bruce Land’s VGA controller and averaging module.  We used the FFT, PLL and SDRAM controller from Altera’s megafunction collection.</p>
        </section>

        <footer>
          Witprocam is maintained by <a href="https://github.com/seanogden">seanogden</a><br>
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>. Tactile theme by <a href="https://twitter.com/jasonlong">Jason Long</a>.
        </footer>

        
      </div>
    </div>
  </body>
</html>